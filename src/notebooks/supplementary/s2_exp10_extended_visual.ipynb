{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45dafa06",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ea03259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Users\\dawson\\Documents\\GitHub\\new-peak-project\\src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path+'/src')\n",
    "print(f'Project path set to: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdab0f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dawson\\Documents\\Google Drive\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data\\new-peak-project\\experiments\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\".env\")\n",
    "print(config[\"DATA_PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9927c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ModelBuilder import ModelBuilder\n",
    "from models.Reaction import Reaction\n",
    "from models.ReactionArchtype import ReactionArchtype\n",
    "from models.ArchtypeCollections import *\n",
    "\n",
    "# import scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# tree models and support vector machines\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# import pearson correlation\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba9afad",
   "metadata": {},
   "source": [
    "## Notebook Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa1b09ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dawson\\Documents\\Google Drive\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data\\new-peak-project\\experiments/s2_exp10_extended_8_5_2/\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "### parameters \n",
    "\n",
    "notebook_name = 's2_exp10_extended' # name of the notebook\n",
    "distortion_scales = [1.1, 1.2, 1.5, 2, 4, 8, 16, 32, 64, 128] # scales for the distortion of the model parameters\n",
    "distortion_ranges = []\n",
    "for scale in distortion_scales:\n",
    "    min_scale = 1 / scale\n",
    "    max_scale = scale\n",
    "    distortion_ranges.append((min_scale, max_scale))\n",
    "    \n",
    "\n",
    "## Generation of ground truth model \n",
    "\n",
    "model_name = 'v4_drug_model' # name of the model\n",
    "o_random_seed = 8\n",
    "# p_overall_seed = 46 # different seed for parameter generation\n",
    "no_observable_species = 5\n",
    "no_feedback_regulations = 2\n",
    "specie_value_range = (1000, 5000)\n",
    "param_range = (0.05, 20)\n",
    "param_multiplier_range = (0.5, 1.5)\n",
    "\n",
    "## Simulation parameters \n",
    "\n",
    "simulation_time = 1000 \n",
    "simulation_step = 100\n",
    "\n",
    "## Feature data generation \n",
    "\n",
    "feature_generation_method = 'lhs'\n",
    "feature_generation_extra_params = {'min': 0.1, 'max': 10}\n",
    "feature_generation_size = 1000 \n",
    "feature_generation_seed = 50 # if -1 then 'o_random_seed' is used\n",
    "if feature_generation_seed == -1:\n",
    "    feature_generation_seed = o_random_seed\n",
    "\n",
    "\n",
    "'''\n",
    "Options: \n",
    "- 'feedback_prune': removes feedback regulations from the model \n",
    "- 'random parameter': randomizes a x% of parameter values of the model\n",
    "'''\n",
    "\n",
    "''' \n",
    "Options: \n",
    "- 'last_time_point' : only the last time point of the phosphorylated species is used\n",
    "- 'dynamic_feature': computes the characteristic 'ten' dynamic feature for each specie data \n",
    "'''\n",
    "\n",
    "## General parameters\n",
    "parallelise = True\n",
    "save_figures = True \n",
    "experiment_id = notebook_name + '_' + str(o_random_seed) + '_' + str(no_observable_species) + '_' + str(no_feedback_regulations)\n",
    "experiment_folder = config['DATA_PATH'] + '/' + experiment_id + '/'\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)\n",
    "    \n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed3292",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1db9e67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID:  s2_exp10_extended_8_5_2\n",
      "Experiment folder:  C:\\Users\\dawson\\Documents\\Google Drive\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data\\new-peak-project\\experiments/s2_exp10_extended_8_5_2/\n",
      "Distortion ranges:  [(0.9090909090909091, 1.1), (0.8333333333333334, 1.2), (0.6666666666666666, 1.5), (0.5, 2), (0.25, 4), (0.125, 8), (0.0625, 16), (0.03125, 32), (0.015625, 64), (0.0078125, 128)]\n"
     ]
    }
   ],
   "source": [
    "print('Experiment ID: ', experiment_id)\n",
    "print('Experiment folder: ', experiment_folder)\n",
    "print('Distortion ranges: ', distortion_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20366889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment Progress: 10it [08:24, 50.42s/it]\n"
     ]
    }
   ],
   "source": [
    "### Virtual Cell Creation\n",
    "# create a drug enabled model \n",
    "from models.Utils import *\n",
    "from models.DrugModelSpecification import DrugModelSpecification, Drug\n",
    "from models.Solver.RoadrunnerSolver import RoadrunnerSolver\n",
    "from models.SyntheticGen import generate_feature_data_v2, generate_target_data_diff_build\n",
    "from models.SyntheticGen import generate_model_timecourse_data_diff_build\n",
    "from models.Utils import last_time_point_method, dynamic_features_method\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "\n",
    "output_data = []\n",
    "for j, dis_range in tqdm(enumerate(distortion_ranges), desc='Experiment Progress'):\n",
    "\n",
    "    model_drug_spec = DrugModelSpecification()\n",
    "    model_drug_spec.generate_specifications(o_random_seed, no_observable_species, no_feedback_regulations, verbose=0)\n",
    "    drug_0 = Drug('D0', 500, 500)\n",
    "    rng = np.random.default_rng(o_random_seed)\n",
    "    # add random 'up' and 'down' regulations to the drug\n",
    "    regulation_dir = []\n",
    "    for i, s in enumerate(model_drug_spec.A_species):\n",
    "        reg_type = str(rng.choice(['up', 'down']))\n",
    "        regulation_dir.append(reg_type)\n",
    "        drug_0.add_regulation(s, reg_type)\n",
    "    model_drug_spec.add_drug(drug_0)\n",
    "    # print(model_drug_spec)\n",
    "    # print(f'Feedback: {model_drug_spec.get_feedback_regulations()}')\n",
    "\n",
    "\n",
    "    p_random_seeds = []\n",
    "    feature_size = 1000 \n",
    "    rng = np.random.default_rng(o_random_seed)\n",
    "    # generate `feature_size` random seeds for different parameter sets using numpy, ensure that the seeds are unique\n",
    "    p_random_seeds = rng.choice(range(1000000), feature_size, replace=False).tolist()\n",
    "\n",
    "    G0_d = model_drug_spec.generate_network('drug_model_524', \n",
    "                                            specie_value_range, \n",
    "                                            param_range, \n",
    "                                            param_multiplier_range,  \n",
    "                                            verbose=0,\n",
    "                                            random_seed=p_random_seeds[0])\n",
    "    base_parameters = G0_d.get_parameters()\n",
    "    base_initial_conditions = G0_d.get_state_variables()\n",
    "\n",
    "    # print(G0_d.get_antimony_model())\n",
    "\n",
    "\n",
    "    # generate parameter sets for each random seed\n",
    "    parameter_sets = []\n",
    "    for p in p_random_seeds: \n",
    "        model_build = model_drug_spec.generate_network(f'param_seed_{p}', \n",
    "                                                specie_value_range, param_range, param_multiplier_range, random_seed=p, verbose=0)\n",
    "        parameter_sets.append(model_build.get_parameters())\n",
    "        \n",
    "    # test simulation \n",
    "\n",
    "\n",
    "\n",
    "    solver = RoadrunnerSolver()\n",
    "    solver.compile(G0_d.get_sbml_model())\n",
    "    # result = solver.simulate(0, 1000, 100)\n",
    "\n",
    "\n",
    "\n",
    "    feature_data = generate_feature_data_v2(model_drug_spec, base_initial_conditions, feature_generation_method, feature_generation_extra_params, 1000, feature_generation_seed)\n",
    "    target_data, _ = generate_target_data_diff_build(model_drug_spec, solver, \n",
    "                                                    feature_data, parameter_sets, \n",
    "                                                    {'start': 0, 'end': 1000, 'points': 100}, \n",
    "                                                    n_cores=1, verbose=False)\n",
    "\n",
    "\n",
    "    # Suboptimal Model Generation\n",
    "\n",
    "    # randomise links and parameters by using a different random seed\n",
    "    new_spec = DrugModelSpecification()\n",
    "    new_spec.generate_specifications(o_random_seed, no_observable_species, no_feedback_regulations, verbose=0)\n",
    "    new_spec.add_drug(drug_0)\n",
    "    new_model = new_spec.generate_network('submodel', specie_value_range, param_range, param_multiplier_range, random_seed=100005352, verbose=0)\n",
    "    new_base_parameters = new_model.get_parameters()\n",
    "    new_base_initial_conditions = new_model.get_state_variables()\n",
    "    new_solver = RoadrunnerSolver()\n",
    "    new_solver.compile(new_model.get_sbml_model())\n",
    "\n",
    "    # Minor distortion of the parameters to create a new set of parameters\n",
    "\n",
    "    rng = np.random.default_rng(o_random_seed)\n",
    "    modified_parameter_sets = []\n",
    "    for params in parameter_sets:\n",
    "        new_params = {}\n",
    "        for key, value in params.items(): \n",
    "            new_params[key] = value * rng.uniform(dis_range[0], dis_range[1]) # distortion range, expectation is that the larger the worse the model performance \n",
    "        modified_parameter_sets.append(new_params)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    new_base_parameters_set = []\n",
    "    for p in p_random_seeds: \n",
    "        new_base_parameters_set.append(new_base_parameters)\n",
    "\n",
    "    # generate the timecourse data for the new model\n",
    "    time_course_data = generate_model_timecourse_data_diff_build(new_spec, \n",
    "                                                    new_solver, \n",
    "                                                    feature_data, \n",
    "                                                    modified_parameter_sets,\n",
    "                                                    {'start': 0, 'end': 1000, 'points': 100}, \n",
    "                                                    capture_species='all', n_cores=1, verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    all_species = model_drug_spec.A_species + model_drug_spec.B_species + model_drug_spec.C_species\n",
    "    all_phos_species = [s+'p' for s in all_species]\n",
    "    # apply the data engineering method to the feature data\n",
    "    last_time_data = last_time_point_method(time_course_data, all_phos_species)\n",
    "\n",
    "    dynamic_data = dynamic_features_method(time_course_data, all_phos_species, n_cores=8)\n",
    "    combined_lp_data = pd.concat([feature_data, last_time_data], axis=1)\n",
    "    combined_dyn_data = pd.concat([feature_data, dynamic_data], axis=1)\n",
    "    feature_data_list = [feature_data, last_time_data, dynamic_data, combined_lp_data, combined_dyn_data]\n",
    "    feature_data_names = ['feature_data', 'last_time_data', 'dynamic_data', 'combined_lp_data', 'combined_dyn_data']\n",
    "\n",
    "\n",
    "    def evaluate_model(model, model_name, feature_data, feature_data_name, target_data, test_size=0.2, random_state=4):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(feature_data, target_data, test_size=test_size, random_state=random_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        # return a dictionary of the model performance\n",
    "        return {'Model': model_name, \n",
    "                'Feature Data': feature_data_name,\n",
    "                'Mean Squared Error': mean_squared_error(y_test, y_pred),\n",
    "                'R2 Score': r2_score(y_test, y_pred),\n",
    "                'Pearson Correlation': pearsonr(y_test, y_pred)[0],\n",
    "                'Pearson P-Value': pearsonr(y_test, y_pred)[1]\n",
    "                }\n",
    "        \n",
    "    # create a linear regression model\n",
    "    lm = LinearRegression()\n",
    "    # create a random forest model\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=o_random_seed)\n",
    "    # create a gradient boosting model\n",
    "    gb = GradientBoostingRegressor(n_estimators=100, random_state=o_random_seed)\n",
    "    # create a support vector machine model\n",
    "    svr = SVR(max_iter=10000)\n",
    "    scaled_svr = Pipeline([('scaler', StandardScaler()), ('svr', svr)])\n",
    "    # create a neural network model (simple)\n",
    "    nn = MLPRegressor(hidden_layer_sizes=(20,), max_iter=10000, random_state=o_random_seed)\n",
    "    scaled_nn = Pipeline([('scaler', StandardScaler()), ('nn', nn)])\n",
    "\n",
    "    all_models = [lm, rf, gb, scaled_svr, scaled_nn]\n",
    "    all_models_desc = ['Linear Regression', 'Random Forest', 'Gradient Boosting', 'Support Vector Machine', 'Neural Network']\n",
    "    zipped_model_data = list(zip(all_models, all_models_desc))\n",
    "    all_features = feature_data_list\n",
    "    all_features_desc = feature_data_names\n",
    "    zipped_feature_data = list(zip(all_features, all_features_desc))\n",
    "\n",
    "    # random states are rand ints between 0 and 10000, for n values \n",
    "    np.random.seed(o_random_seed)\n",
    "    n_random = 10\n",
    "    all_random_states = np.random.randint(0, 10000, n_random)\n",
    "\n",
    "    parallelise = True \n",
    "    from tqdm import tqdm\n",
    "    # tqdm is a progress bar library, use it to show the progress of the model evaluation\n",
    "    metric_data = []\n",
    "    if not parallelise:          \n",
    "        for (feature_data, feature_data_name) in tqdm(zipped_feature_data):\n",
    "            # print('Feature Data:', feature_data_name)\n",
    "            # print('Feature Data Shape:', feature_data.shape)\n",
    "            for (model, model_name) in zipped_model_data:\n",
    "                # print('Model:', model_name)\n",
    "                for rand in all_random_states:\n",
    "                    metrics = evaluate_model(model, model_name, feature_data, feature_data_name, target_data['Cp'], random_state=rand)\n",
    "                    metric_data.append(metrics)\n",
    "                    \n",
    "    else:        \n",
    "        # parallelise the model evaluation process using joblib\n",
    "        \n",
    "        metric_data = Parallel(n_jobs=-1)(delayed(evaluate_model)(model, model_name, feature_data, feature_data_name, target_data['Cp'], random_state=rand) \n",
    "                                        for (feature_data, feature_data_name) in zipped_feature_data\n",
    "                                        for (model, model_name) in zipped_model_data\n",
    "                                        for rand in all_random_states)\n",
    "\n",
    "    # make a dataframe of the metric data\n",
    "    metric_df = pd.DataFrame(metric_data)\n",
    "    \n",
    "    exp_group = str(distortion_scales[j])\n",
    "    # create a new column for the distortion scale\n",
    "    metric_df['Distortion Scale'] = exp_group\n",
    "    output_data.append(metric_df)\n",
    "    \n",
    "    # save metric_df to a pickle file\n",
    "    output_file = experiment_folder + f'metric_data_{exp_group}.pkl'\n",
    "    metric_df.to_pickle(output_file)\n",
    "    # print(f'Saved metric data to {output_file}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba16dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Distortion scale mismatch! Expected 1.1, but got 4.\n",
      "Loading metric data for scale 4 from file...\n",
      "Warning: Distortion scale mismatch! Expected 1.2, but got 4.\n",
      "Loading metric data for scale 4 from file...\n",
      "Warning: Distortion scale mismatch! Expected 1.5, but got 4.\n",
      "Loading metric data for scale 4 from file...\n",
      "Warning: Distortion scale mismatch! Expected 2, but got 4.\n",
      "Loading metric data for scale 4 from file...\n",
      "Loading metric data for scale 4 from file...\n",
      "Warning: Distortion scale mismatch! Expected 8, but got 4.\n",
      "Loading metric data for scale 4 from file...\n",
      "Warning: Distortion scale mismatch! Expected 16, but got 4.\n",
      "Loading metric data for scale 4 from file...\n",
      "Warning: Distortion scale mismatch! Expected 32, but got 4.\n",
      "Loading metric data for scale 4 from file...\n",
      "Warning: Distortion scale mismatch! Expected 64, but got 4.\n",
      "Loading metric data for scale 4 from file...\n",
      "Warning: Distortion scale mismatch! Expected 128, but got 4.\n",
      "Loading metric data for scale 4 from file...\n",
      "All data loaded successfully. Producing final output dataframe.\n"
     ]
    }
   ],
   "source": [
    "output_df = pd.DataFrame()\n",
    "all_loaded = True\n",
    "\n",
    "for i, df in enumerate(output_data):\n",
    "    # load the metric data for each scale\n",
    "    exp_group = df.iloc[0]['Distortion Scale']  # get the distortion scale from the first row of the dataframe\n",
    "    curr_scale = str(distortion_scales[i])\n",
    "    \n",
    "    if exp_group != curr_scale:\n",
    "        print(f'Warning: Distortion scale mismatch! Expected {curr_scale}, but got {exp_group}.')\n",
    "        all_loaded = False\n",
    "    # if the file exists, load it\n",
    "    if os.path.exists(experiment_folder + f'metric_data_{exp_group}.pkl'):\n",
    "        print(f'Loading metric data for scale {exp_group} from file...')\n",
    "        df = pd.read_pickle(experiment_folder + f'metric_data_{exp_group}.pkl')\n",
    "        all_loaded = True\n",
    "    else:\n",
    "        print(f'File not found for scale {exp_group}, there is missing data for this scale.')\n",
    "        all_loaded = False\n",
    "        break \n",
    "\n",
    "    if not all_loaded:\n",
    "        break\n",
    "        \n",
    "    output_df = pd.concat([output_df, df], ignore_index=True)\n",
    "\n",
    "if not all_loaded:\n",
    "    print('Not all data was loaded successfully, please check the files.')\n",
    "else:\n",
    "    print('All data loaded successfully. Producing final output dataframe.')\n",
    "    # save the output_df to a pickle file\n",
    "    output_file = experiment_folder + 'final_output_df.pkl'\n",
    "    output_df.to_pickle(output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
