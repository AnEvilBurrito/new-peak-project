{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45dafa06",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ea03259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path set to: c:\\Github\\new-peak-project\\src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path+'/src')\n",
    "print(f'Project path set to: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdab0f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data\\new-peak-project\\experiments\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\".env\")\n",
    "print(config[\"DATA_PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9927c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ModelBuilder import ModelBuilder\n",
    "from models.Reaction import Reaction\n",
    "from models.ReactionArchtype import ReactionArchtype\n",
    "from models.ArchtypeCollections import *\n",
    "\n",
    "# import scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# tree models and support vector machines\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# import pearson correlation\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba9afad",
   "metadata": {},
   "source": [
    "## Notebook Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eef2cf",
   "metadata": {},
   "source": [
    "Aim is to discover feature datasets which is predictive for the drug target (>0.5 pearson correlation between predicted to actual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa1b09ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data\\new-peak-project\\experiments/exp11_model_search_1/\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "### parameters \n",
    "\n",
    "notebook_name = 'exp11_model_search' # name of the notebook\n",
    "try_seeds = []\n",
    "for i in range(1, 101):\n",
    "    try_seeds.append(i)\n",
    "    \n",
    "\n",
    "## Generation of ground truth model \n",
    "\n",
    "model_name = 'v4_drug_model' # name of the model\n",
    "# p_overall_seed = 46 # different seed for parameter generation\n",
    "no_observable_species = 100\n",
    "no_feedback_regulations = 20\n",
    "specie_value_range = (1000, 5000)\n",
    "param_range = (0.05, 20)\n",
    "param_multiplier_range = (0.5, 1.5)\n",
    "\n",
    "## Simulation parameters \n",
    "\n",
    "simulation_time = 1000 \n",
    "simulation_step = 100\n",
    "\n",
    "## Feature data generation \n",
    "\n",
    "feature_generation_method = 'lhs'\n",
    "feature_generation_extra_params = {'min': 0.1, 'max': 10}\n",
    "feature_generation_size = 1000 \n",
    "feature_generation_seed = 50 # if -1 then 'o_random_seed' is used\n",
    "\n",
    "\n",
    "'''\n",
    "Options: \n",
    "- 'feedback_prune': removes feedback regulations from the model \n",
    "- 'random parameter': randomizes a x% of parameter values of the model\n",
    "'''\n",
    "\n",
    "''' \n",
    "Options: \n",
    "- 'last_time_point' : only the last time point of the phosphorylated species is used\n",
    "- 'dynamic_feature': computes the characteristic 'ten' dynamic feature for each specie data \n",
    "'''\n",
    "\n",
    "## General parameters\n",
    "parallelise = True\n",
    "save_figures = True \n",
    "exp_id = '1'\n",
    "experiment_id = notebook_name + '_' + str(exp_id)\n",
    "experiment_folder = config['DATA_PATH'] + '/' + experiment_id + '/'\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)\n",
    "    \n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed3292",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db9e67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID:  exp11_model_search_1\n",
      "Experiment folder:  G:\\My Drive\\DAWSON PHD PROJECT\\Biomarker Data Repository\\data\\new-peak-project\\experiments/exp11_model_search_1/\n",
      "Tried seeds:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n"
     ]
    }
   ],
   "source": [
    "print('Experiment ID: ', experiment_id)\n",
    "print('Experiment folder: ', experiment_folder)\n",
    "print('Tried seeds: ', try_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20366889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment Progress: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment Progress: 10it [17:23, 104.33s/it]\n"
     ]
    }
   ],
   "source": [
    "### Virtual Cell Creation\n",
    "# create a drug enabled model \n",
    "from models.Utils import *\n",
    "from models.DrugModelSpecification import DrugModelSpecification, Drug\n",
    "from models.Solver.RoadrunnerSolver import RoadrunnerSolver\n",
    "from models.SyntheticGen import generate_feature_data_v2, generate_target_data_diff_build\n",
    "from models.SyntheticGen import generate_model_timecourse_data_diff_build\n",
    "from models.Utils import last_time_point_method, dynamic_features_method\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "\n",
    "output_data = []\n",
    "for j, seed in tqdm(enumerate(try_seeds), desc='Experiment Progress'):\n",
    "\n",
    "    model_drug_spec = DrugModelSpecification()\n",
    "    model_drug_spec.generate_specifications(seed, no_observable_species, no_feedback_regulations, verbose=0)\n",
    "    drug_0 = Drug('D0', 500, 500)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # add random 'up' and 'down' regulations to the drug\n",
    "    regulation_dir = []\n",
    "    for i, s in enumerate(model_drug_spec.A_species):\n",
    "        reg_type = str(rng.choice(['up', 'down']))\n",
    "        regulation_dir.append(reg_type)\n",
    "        drug_0.add_regulation(s, reg_type)\n",
    "    model_drug_spec.add_drug(drug_0)\n",
    "    # print(model_drug_spec)\n",
    "    # print(f'Feedback: {model_drug_spec.get_feedback_regulations()}')\n",
    "\n",
    "\n",
    "    p_random_seeds = []\n",
    "    feature_size = 1000 \n",
    "    rng = np.random.default_rng(seed)\n",
    "    # generate `feature_size` random seeds for different parameter sets using numpy, ensure that the seeds are unique\n",
    "    p_random_seeds = rng.choice(range(1000000), feature_size, replace=False).tolist()\n",
    "\n",
    "    G0_d = model_drug_spec.generate_network('drug_model_524', \n",
    "                                            specie_value_range, \n",
    "                                            param_range, \n",
    "                                            param_multiplier_range,  \n",
    "                                            verbose=0,\n",
    "                                            random_seed=p_random_seeds[0])\n",
    "    base_parameters = G0_d.get_parameters()\n",
    "    base_initial_conditions = G0_d.get_state_variables()\n",
    "\n",
    "    # print(G0_d.get_antimony_model())\n",
    "\n",
    "\n",
    "    # generate parameter sets for each random seed\n",
    "    parameter_sets = []\n",
    "    for p in p_random_seeds: \n",
    "        model_build = model_drug_spec.generate_network(f'param_seed_{p}', \n",
    "                                                specie_value_range, param_range, param_multiplier_range, random_seed=p, verbose=0)\n",
    "        parameter_sets.append(model_build.get_parameters())\n",
    "        \n",
    "    # test simulation \n",
    "\n",
    "\n",
    "\n",
    "    solver = RoadrunnerSolver()\n",
    "    solver.compile(G0_d.get_sbml_model())\n",
    "    # result = solver.simulate(0, 1000, 100)\n",
    "\n",
    "\n",
    "\n",
    "    feature_data = generate_feature_data_v2(model_drug_spec, base_initial_conditions, feature_generation_method, feature_generation_extra_params, 1000, feature_generation_seed)\n",
    "    target_data, _ = generate_target_data_diff_build(model_drug_spec, solver, \n",
    "                                                    feature_data, parameter_sets, \n",
    "                                                    {'start': 0, 'end': 1000, 'points': 100}, \n",
    "                                                    n_cores=1, verbose=False)\n",
    "\n",
    "\n",
    "    # create a dataframe with the feature data and target data\n",
    "    feature_data_df = pd.DataFrame(feature_data)\n",
    "    target_data_df = pd.DataFrame(target_data)\n",
    "    # add the target data to the feature data\n",
    "    feature_data_df['target'] = target_data_df['Cp']\n",
    "\n",
    "    # calculate the correlation between the features and the target data\n",
    "    correlation = feature_data_df.corr()['target'].sort_values(ascending=False)\n",
    "    # create a dataframe with the correlation values\n",
    "    correlation_df = pd.DataFrame(correlation)\n",
    "    \n",
    "    mean = np.mean(correlation_df['correlation'])\n",
    "    std = np.std(correlation_df['correlation'])\n",
    "    max_val = np.max(correlation_df['correlation'])\n",
    "    min_val = np.min(correlation_df['correlation'])\n",
    "    outliers = correlation_df[(correlation_df['correlation'] > mean + 3*std) | (correlation_df['correlation'] < mean - 3*std)]\n",
    "    outliers_ratio = outliers.shape[0] / correlation_df.shape[0]\n",
    "    \n",
    "    # build a dataframe based on the above values\n",
    "    data = {\n",
    "        'seed': seed,\n",
    "        'mean': mean,\n",
    "        'std': std,\n",
    "        'max': max_val,\n",
    "        'min': min_val,\n",
    "        'outliers_ratio': outliers_ratio,\n",
    "    }\n",
    "    output_data.append(data)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3dbcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe from the output data\n",
    "output_data_df = pd.DataFrame(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b1d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835f9c4b",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
