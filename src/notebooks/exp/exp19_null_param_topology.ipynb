{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e83cd3e2",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f52c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "# find the string 'project' in the path, return index\n",
    "index_project = path.find('project')\n",
    "# slice the path from the index of 'project' to the end\n",
    "project_path = path[:index_project+7]\n",
    "# set the working directory\n",
    "os.chdir(project_path+'/src')\n",
    "print(f'Project path set to: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3257459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\".env\")\n",
    "print(config[\"DATA_PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d929667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ModelBuilder import ModelBuilder\n",
    "from models.Reaction import Reaction\n",
    "from models.ReactionArchtype import ReactionArchtype\n",
    "from models.ArchtypeCollections import *\n",
    "\n",
    "# import scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# tree models and support vector machines\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# import pearson correlation\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52ed69f",
   "metadata": {},
   "source": [
    "## Notebook Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7759f7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "### parameters \n",
    "\n",
    "notebook_name = 'exp19_model_topology' # name of the notebook\n",
    "\n",
    "## Generation of ground truth model \n",
    "\n",
    "model_name = 'v4_drug_model' # name of the model\n",
    "o_random_seed = 53252\n",
    "# p_overall_seed = 46 # different seed for parameter generation\n",
    "no_observable_species = 13\n",
    "no_feedback_regulations = 7\n",
    "specie_value_range = (1000, 5000)\n",
    "param_range = (0.8, 1.2)\n",
    "param_multiplier_range = (0.99, 1.01)\n",
    "\n",
    "\n",
    "## Simulation parameters \n",
    "\n",
    "simulation_time = 1000 \n",
    "simulation_step = 100\n",
    "\n",
    "## Feature data generation \n",
    "\n",
    "feature_generation_method = 'lhs'\n",
    "feature_generation_extra_params = {'min': 0.1, 'max': 10}\n",
    "feature_generation_size = 1000 \n",
    "feature_generation_seed = 50 # if -1 then 'o_random_seed' is used\n",
    "if feature_generation_seed == -1:\n",
    "    feature_generation_seed = o_random_seed\n",
    "    \n",
    "## Data engineering parameters\n",
    "\n",
    "# Suboptimal Model Generation \n",
    "\n",
    "'''\n",
    "Options: \n",
    "- 'feedback_prune': removes feedback regulations from the model \n",
    "- 'random parameter': randomizes a x% of parameter values of the model\n",
    "'''\n",
    "\n",
    "''' \n",
    "Options: \n",
    "- 'last_time_point' : only the last time point of the phosphorylated species is used\n",
    "- 'dynamic_feature': computes the characteristic 'ten' dynamic feature for each specie data \n",
    "'''\n",
    "\n",
    "## General parameters\n",
    "parallelise = True\n",
    "save_figures = True \n",
    "experiment_id = notebook_name + '_' + str(o_random_seed) + '_' + str(feature_generation_seed)\n",
    "experiment_folder = config['DATA_PATH'] + '/' + experiment_id + '/'\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)\n",
    "    \n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89646e",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c12c7e",
   "metadata": {},
   "source": [
    "### Virtual Cell Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebfd82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a drug enabled model \n",
    "from models.Utils import *\n",
    "from models.DrugModelSpecification import DrugModelSpecification, Drug\n",
    "\n",
    "model_drug_spec = DrugModelSpecification()\n",
    "model_drug_spec.generate_specifications(o_random_seed, no_observable_species, no_feedback_regulations, verbose=0)\n",
    "drug_0 = Drug('D0', 500, 500)\n",
    "rng = np.random.default_rng(o_random_seed)\n",
    "# add random 'up' and 'down' regulations to the drug\n",
    "regulation_dir = []\n",
    "for i, s in enumerate(model_drug_spec.A_species):\n",
    "    reg_type = str(rng.choice(['up', 'down']))\n",
    "    regulation_dir.append(reg_type)\n",
    "    drug_0.add_regulation(s, reg_type)\n",
    "model_drug_spec.add_drug(drug_0)\n",
    "print(model_drug_spec)\n",
    "print(f'Feedback: {model_drug_spec.get_feedback_regulations()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231acc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_random_seeds = []\n",
    "feature_size = 1000 \n",
    "rng = np.random.default_rng(o_random_seed)\n",
    "# generate `feature_size` random seeds for different parameter sets using numpy, ensure that the seeds are unique\n",
    "p_random_seeds = rng.choice(range(1000000), feature_size, replace=False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab188a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "G0_d = model_drug_spec.generate_network('drug_model_524', \n",
    "                                        specie_value_range, \n",
    "                                        param_range, \n",
    "                                        param_multiplier_range,  \n",
    "                                        verbose=0,\n",
    "                                        random_seed=p_random_seeds[0])\n",
    "base_parameters = G0_d.get_parameters()\n",
    "base_initial_conditions = G0_d.get_state_variables()\n",
    "\n",
    "print(G0_d.get_antimony_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e35100",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_sets = []\n",
    "for p in p_random_seeds: \n",
    "    model_build = model_drug_spec.generate_network(f'param_seed_{p}', \n",
    "                                            specie_value_range, param_range, param_multiplier_range, random_seed=p, verbose=0)\n",
    "    parameter_sets.append(model_build.get_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea31a701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test simulation \n",
    "\n",
    "from models.Solver.RoadrunnerSolver import RoadrunnerSolver\n",
    "\n",
    "solver = RoadrunnerSolver()\n",
    "solver.compile(G0_d.get_sbml_model())\n",
    "\n",
    "original_result = solver.simulate(0, 1000, 100)\n",
    "original_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a76312",
   "metadata": {},
   "source": [
    "### Perform parameter sensitivity analysis on original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "original_cp = original_result['Cp']\n",
    "sensitivity_summary = []\n",
    "parameters_list = G0_d.get_parameters()\n",
    "\n",
    "for key, value in parameters_list.items():\n",
    "    factor_range = np.arange(0.9, 1.11, 0.02)\n",
    "    for factor in factor_range:\n",
    "        new_value = value * factor\n",
    "        solver.set_parameter_values({key: new_value})\n",
    "        result = solver.simulate(0, 1000, 100)\n",
    "        perturbed_cp = result['Cp']\n",
    "        \n",
    "        # Calculate RMSE or other metric\n",
    "        euclid_norm = np.linalg.norm(original_cp - perturbed_cp)\n",
    "        \n",
    "        # Store result\n",
    "        sensitivity_summary.append({\n",
    "            'parameter': key,\n",
    "            'factor': factor,\n",
    "            'rmse': euclid_norm,\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "sensitivity_df = pd.DataFrame(sensitivity_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c187ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean Euclidean norm per parameter\n",
    "rank_df = sensitivity_df.groupby('parameter')['rmse'].mean().reset_index()\n",
    "rank_df = rank_df.sort_values(by='rmse', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2155605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute mean Euclidean norm and sort\n",
    "rank_df = (\n",
    "    sensitivity_df.groupby('parameter')['rmse']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(by='rmse', ascending=False)\n",
    ")\n",
    "\n",
    "# Select top 10\n",
    "top10_df = rank_df.head(10)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "sns.barplot(\n",
    "    data=top10_df,\n",
    "    x='rmse',\n",
    "    y='parameter',\n",
    "    hue='parameter',\n",
    "    palette='Blues_r',\n",
    ")\n",
    "\n",
    "plt.title(\"Top 10 Most Sensitive Parameters (Mean Euclidean Norm of Cp)\")\n",
    "plt.xlabel(\"Mean Euclidean Norm\")\n",
    "plt.ylabel(\"Parameter\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def infer_phosphorylation_map(antimony_str):\n",
    "    \"\"\"\n",
    "    Infers base species to phosphorylated form based on 'Xp' species in the model.\n",
    "    \"\"\"\n",
    "    # Match all species names (A0, A0p, etc.)\n",
    "    species = set(re.findall(r'\\b[A-Za-z]\\w*\\b', antimony_str))\n",
    "    \n",
    "    mapping = {}\n",
    "    for sp in species:\n",
    "        if sp.endswith('p'):\n",
    "            base = sp[:-1]\n",
    "            if base in species:\n",
    "                mapping[base] = sp\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def map_regulations_to_parameters(antimony_str, regulations, regulation_types=None):\n",
    "    \"\"\"\n",
    "    Map each regulation to its controlling parameters based on rate laws in the Antimony model.\n",
    "    \n",
    "    Parameters:\n",
    "        antimony_str (str): Antimony model string.\n",
    "        regulations (list of tuples): Each tuple is (regulator, target).\n",
    "        regulation_types (list of str, optional): 'up' or 'down' for each regulation.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns: ['regulator', 'target', 'type', 'parameters']\n",
    "    \"\"\"\n",
    "    # Map regulators to their phosphorylated forms\n",
    "    phosphorylated_form = infer_phosphorylation_map(antimony_str)\n",
    "\n",
    "    # Parse reactions\n",
    "    pattern = re.compile(r'(J\\d+):\\s*(\\w+)\\s*->\\s*(\\w+);\\s*(.*)')\n",
    "    reactions = pattern.findall(antimony_str)\n",
    "    \n",
    "    # Map target species to associated rate expressions\n",
    "    target_to_rates = defaultdict(list)\n",
    "    for rxn_id, reactant, product, rate_expr in reactions:\n",
    "        target_to_rates[reactant].append((rxn_id, rate_expr))\n",
    "    \n",
    "    results = []\n",
    "    for i, (reg, tgt) in enumerate(regulations):\n",
    "        reg_form = phosphorylated_form.get(reg, reg)\n",
    "        r_type = regulation_types[i] if regulation_types else \"unknown\"\n",
    "        matched_params = set()\n",
    "\n",
    "        # Search all rate expressions that involve the target\n",
    "        for rxn_id, rate_expr in target_to_rates.get(tgt, []):\n",
    "            # Match: reg_form * param or param * reg_form\n",
    "            matches = re.findall(\n",
    "                rf'\\b{reg_form}\\b\\s*\\*\\s*(\\w+)|(\\w+)\\s*\\*\\s*\\b{reg_form}\\b',\n",
    "                rate_expr\n",
    "            )\n",
    "            found = [m[0] or m[1] for m in matches if m[0] or m[1]]\n",
    "            matched_params.update(found)\n",
    "\n",
    "        results.append({\n",
    "            'regulator': reg,\n",
    "            'target': tgt,\n",
    "            'type': r_type,\n",
    "            'parameters': sorted(matched_params) if matched_params else None\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225ee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_phosphorylation_as_regulations(antimony_str):\n",
    "    \"\"\"\n",
    "    Extract phosphorylation reactions as regulator-target pairs with Vmax/Km.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame with columns: ['regulator', 'target', 'type', 'parameters']\n",
    "    \"\"\"\n",
    "    rxn_pattern = re.compile(r'(J\\d+):\\s*(\\w+)\\s*->\\s*(\\w+);\\s*(.*)')\n",
    "    reactions = rxn_pattern.findall(antimony_str)\n",
    "\n",
    "    records = []\n",
    "    for rxn_id, reactant, product, rate_expr in reactions:\n",
    "        # Heuristic: phosphorylation if product ends with 'p' and matches reactant + 'p'\n",
    "        if product.endswith('p') and reactant == product[:-1]:\n",
    "            vmax_match = re.search(r'([A-Za-z0-9_]*Vmax)', rate_expr)\n",
    "            km_match = re.search(r'([A-Za-z0-9_]*Km)', rate_expr)\n",
    "\n",
    "            vmax = vmax_match.group(1) if vmax_match else None\n",
    "            km = km_match.group(1) if km_match else None\n",
    "            params = list(filter(None, [vmax, km]))\n",
    "\n",
    "            records.append({\n",
    "                'regulator': reactant,\n",
    "                'target': product,\n",
    "                'type': 'phosphorylation',\n",
    "                'parameters': params if params else None\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "regulations = model_drug_spec.regulations\n",
    "regulation_types = model_drug_spec.regulation_types\n",
    "\n",
    "df = map_regulations_to_parameters(\n",
    "    G0_d.get_antimony_model(),\n",
    "    regulations,\n",
    "    regulation_types\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade3e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79953d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phospho_reg_df = extract_phosphorylation_as_regulations(G0_d.get_antimony_model())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595d0cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "phospho_reg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b91f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join two df into a new df called 'regulation_df' \n",
    "regulation_df = pd.concat([df, phospho_reg_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e51054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_regulations_by_sensitivity(sensitivity_df, regulation_df):\n",
    "    \"\"\"\n",
    "    Join sensitivity scores to regulations based on parameter names,\n",
    "    and rank regulations by max sensitivity of any associated parameter.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with ['regulator', 'target', 'type', 'parameters', 'mean_rmse', 'max_rmse']\n",
    "    \"\"\"\n",
    "    # Explode regulation parameters\n",
    "    exploded = regulation_df.explode('parameters').dropna(subset=['parameters'])\n",
    "    exploded = exploded.rename(columns={'parameters': 'parameter'})\n",
    "\n",
    "    # Join with sensitivity values\n",
    "    merged = pd.merge(exploded, sensitivity_df, on='parameter', how='left')\n",
    "\n",
    "    # Aggregate sensitivity per regulation\n",
    "    ranked = (\n",
    "        merged.groupby(['regulator', 'target', 'type'])\n",
    "        .agg(\n",
    "            parameters=('parameter', lambda x: sorted(set(x))),\n",
    "            mean_rmse=('rmse', 'mean'),\n",
    "            max_rmse=('rmse', 'max')\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values(by='max_rmse', ascending=False)\n",
    "    )\n",
    "\n",
    "    return ranked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e755b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = G0_d.get_antimony_model() \n",
    "\n",
    "# Combine both regulation + phosphorylation regulation tables\n",
    "all_regulations_df = pd.concat([\n",
    "    map_regulations_to_parameters(model_str, regulations, regulation_types),\n",
    "    extract_phosphorylation_as_regulations(model_str)\n",
    "], ignore_index=True)\n",
    "\n",
    "# Rank regulations\n",
    "ranked_regs = rank_regulations_by_sensitivity(sensitivity_df, all_regulations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd37980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_top_sensitive_regulations(ranked_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Plot bar chart of top sensitive regulations by max_rmse.\n",
    "    \"\"\"\n",
    "    # Create a readable label for the regulation\n",
    "    ranked_df['label'] = ranked_df['regulator'] + \" → \" + ranked_df['target'] + \" (\" + ranked_df['type'] + \")\"\n",
    "\n",
    "    # Select top N\n",
    "    top_df = ranked_df.nlargest(top_n, 'mean_rmse')\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "    sns.barplot(\n",
    "        data=top_df,\n",
    "        x='mean_rmse',\n",
    "        y='label',\n",
    "        palette='Reds_r',\n",
    "        hue='label',\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Mean Euclidean Norm (Cp deviation)\")\n",
    "    plt.ylabel(\"Regulation\")\n",
    "    plt.title(f\"Top {top_n} Most Sensitive Regulations\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a768628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_sensitive_regulations(ranked_regs, top_n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe79a38",
   "metadata": {},
   "source": [
    "### Generate synthetic 'omics-like' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d945cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SyntheticGen import generate_feature_data, generate_target_data, generate_feature_data_v2, generate_target_data_diff_build\n",
    "\n",
    "feature_data = generate_feature_data_v2(model_drug_spec, base_initial_conditions, feature_generation_method, feature_generation_extra_params, 1000, feature_generation_seed)\n",
    "target_data, _ = generate_target_data_diff_build(model_drug_spec, solver, \n",
    "                                                 feature_data, parameter_sets, \n",
    "                                                 {'start': 0, 'end': 1000, 'points': 100}, \n",
    "                                                 n_cores=1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf28c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(feature_data, config[\"DATA_PATH\"] + \"/presentations/feature_data_v1.pkl\")\n",
    "pd.to_pickle(target_data, config[\"DATA_PATH\"] + \"/presentations/target_data_v1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f87dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the association between the features and the target data in a bar chart based on the correlation values \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# create a dataframe with the feature data and target data\n",
    "feature_data_df = pd.DataFrame(feature_data)\n",
    "target_data_df = pd.DataFrame(target_data)\n",
    "# add the target data to the feature data\n",
    "feature_data_df['target'] = target_data_df['Cp']\n",
    "\n",
    "# calculate the correlation between the features and the target data\n",
    "correlation = feature_data_df.corr()['target'].sort_values(ascending=False)\n",
    "# create a dataframe with the correlation values\n",
    "correlation_df = pd.DataFrame(correlation)\n",
    "correlation_df = correlation_df.reset_index()\n",
    "correlation_df.columns = ['feature', 'correlation']\n",
    "# do not include the target data in the correlation dataframe\n",
    "correlation_df = correlation_df[correlation_df['feature'] != 'target']\n",
    "abs_correlation_df = correlation_df.copy()\n",
    "# take the absolute value of the correlation\n",
    "abs_correlation_df['correlation'] = abs(abs_correlation_df['correlation'])\n",
    "# sort the dataframe by the absolute value of the correlation\n",
    "abs_correlation_df = abs_correlation_df.sort_values(by='correlation', ascending=False)\n",
    "abs_correlation_df_50 = abs_correlation_df.head(50)\n",
    "\n",
    "sns.set_context(\"talk\", rc={\"font\": \"Arial\"})\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# plot the correlation values\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x='feature', y='correlation', data=abs_correlation_df_50)\n",
    "plt.title('Correlation between features and target data')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Abs Pearson Correlation')\n",
    "plt.xticks(rotation=90, fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a histogram of the correlation values\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.histplot(abs_correlation_df['correlation'], bins=50, kde=True)\n",
    "plt.title('Histogram of Absolute correlation values')\n",
    "plt.xlabel('Abs Pearson Correlation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee1fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a histogram of the correlation values\n",
    "sns.set_context(\"talk\", rc={\"font\": \"Arial\"})\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(8, 4), dpi=300)\n",
    "sns.histplot(correlation_df['correlation'], bins=50, kde=True)\n",
    "plt.title('Histogram of correlation values')\n",
    "plt.xlabel('Abs Pearson Correlation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(-0.5,0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ccb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the mean and standard deviation of the correlation values\n",
    "mean = np.mean(correlation_df['correlation'])\n",
    "std = np.std(correlation_df['correlation'])\n",
    "max_val = np.max(correlation_df['correlation'])\n",
    "min_val = np.min(correlation_df['correlation'])\n",
    "outliers = correlation_df[(correlation_df['correlation'] > mean + 3*std) | (correlation_df['correlation'] < mean - 3*std)]\n",
    "\n",
    "print(f'Mean: {mean:.4f}')\n",
    "print(f'Standard Deviation: {std:.4f}')\n",
    "print(f'Max: {max_val:.4f}')\n",
    "print(f'Min: {min_val:.4f}')\n",
    "print(f'Outliers as a ratio of all features: {outliers.shape[0] / correlation_df.shape[0]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot association between the features and the target data \n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for each feature, plot the association with the target data, which is only a series \n",
    "# plot all features in separate subplots\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\", font_scale=1.5) \n",
    "\n",
    "n_features = len(feature_data.columns)\n",
    "# plot only the top 10 features based on the absolute correlation values\n",
    "top_features = abs_correlation_df['feature'].values[:10]\n",
    "# create a new dataframe with only the top features\n",
    "top_feature_data = feature_data[top_features]\n",
    "print(f'{len(top_feature_data.columns)} features selected based on correlation with target data')\n",
    "# make a subplot based on the size of feature_data, have five columns and as many rows as needed\n",
    "top_n_features = len(top_feature_data.columns)\n",
    "n_rows = int(top_n_features / 5) if top_n_features % 5 == 0 else int(top_n_features / 5) + 1\n",
    "n_cols = 5\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(20, n_rows*4))\n",
    "axs = axs.flatten()\n",
    "\n",
    "\n",
    "# plot each feature in a separate subplot\n",
    "for i, feature in enumerate(top_feature_data.columns):\n",
    "    x = top_feature_data[feature].values.ravel()  # ensure 1D\n",
    "    y = target_data.values.ravel()            # ensure 1D\n",
    "    axs[i].scatter(x, y, alpha=0.5)\n",
    "    # add a dash linear regression line with a pearson correlation coefficient\n",
    "    # compute the pearson correlation coefficient\n",
    "    corr, _ = pearsonr(x, y)\n",
    "    # add a linear regression line\n",
    "    model = LinearRegression()\n",
    "    model.fit(x.reshape(-1, 1), y)\n",
    "    y_pred = model.predict(x.reshape(-1, 1))\n",
    "    axs[i].plot(x, y_pred, color='red', linestyle='--', linewidth=2)\n",
    "    axs[i].set_title(f'{feature} (r={corr:.2f})')\n",
    "\n",
    "    axs[i].set_xlabel('Feature value')\n",
    "    axs[i].set_ylabel('Target value')\n",
    "    axs[i].grid()\n",
    "    # set the x and y limits to be the same for all subplots\n",
    "    max_feature = top_feature_data[feature].values.max()   \n",
    "    max_target = target_data.values.max()  \n",
    "    axs[i].set_xlim([0,max_feature])\n",
    "    axs[i].set_ylim([0,max_target])\n",
    "    # compute the correlation between the feature and target data\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f65b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the target data only with the x axis being 0 to 100 \n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(target_data, bins=100, alpha=0.5, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc12ae",
   "metadata": {},
   "source": [
    "### Suboptimal Model Creation\n",
    "\n",
    "#### If modifying at the model architectural level\n",
    "\n",
    "Mostly done to modify the `ModelSpec` object, where the updated spec information is transferred to a new `ModelBuilder` object, which then need to transpile to Antimony/SBML for a Solver instance. \n",
    "\n",
    "NewSpec --> NewBuilder --> Update parameters to original builder --> Transpile to Antimony/SBML --> Solver instance\n",
    "\n",
    "#### If only changes to states and parameters are needed\n",
    "\n",
    "Simply duplicate the `ModelBuilder` object and update the states and parameters.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14fcaf7",
   "metadata": {},
   "source": [
    "#### Vary different specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e488ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_list = G0_d.get_parameters()\n",
    "# make all parameters to zero\n",
    "zero_parameter_list = {k: 0 for k in parameter_list.keys() if 'Km' not in k}\n",
    "# make 1000 copies of the zero parameter list\n",
    "zero_parameter_sets = [deepcopy(zero_parameter_list) for _ in range(1000)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76792879",
   "metadata": {},
   "source": [
    "#### Vary by removing specific parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df80d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by mean rmse\n",
    "ranked_regs = ranked_regs.sort_values(by='mean_rmse', ascending=False)\n",
    "ranked_regs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6e2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_link_removal_parameters = []\n",
    "parameters_to_zero = set()\n",
    "# iterate ranked_regs from the top and remove the parameters that are in the zero_parameter_sets\n",
    "for index, row in ranked_regs.iterrows():\n",
    "    link_removal_parameter_sets = []\n",
    "    parameters = row['parameters']\n",
    "    for param in parameters:\n",
    "        # if the parameter comtains 'Km' then skip it\n",
    "        if 'Km' in param:\n",
    "            continue\n",
    "        parameters_to_zero.add(param)\n",
    "    print(f'length of parameters to zero: {len(parameters_to_zero)}')\n",
    "    for all_params in parameter_sets:\n",
    "        if parameters is not None:\n",
    "            new_params = all_params.copy()\n",
    "            for zero_param in parameters_to_zero:\n",
    "                if zero_param in all_params:\n",
    "                    new_params[zero_param] = 0\n",
    "            link_removal_parameter_sets.append(new_params)\n",
    "    all_link_removal_parameters.append(link_removal_parameter_sets)\n",
    "    \n",
    "print(f'Number of link removal parameter sets: {len(all_link_removal_parameters)}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f78f2",
   "metadata": {},
   "source": [
    "### Simulation / Extract dynamic feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6183cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minor distortion of the parameters to create a new set of parameters\n",
    "\n",
    "rng = np.random.default_rng(o_random_seed)\n",
    "modified_parameter_sets = []\n",
    "for params in parameter_sets:\n",
    "    new_params = {}\n",
    "    for key, value in params.items(): \n",
    "        new_params[key] = value * rng.uniform(0.25, 4) # distortion range, expectation is that the larger the worse the model performance \n",
    "    modified_parameter_sets.append(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b539d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SyntheticGen import generate_model_timecourse_data_diff_build\n",
    "\n",
    "# generate the timecourse data for the new model\n",
    "time_course_data = generate_model_timecourse_data_diff_build(model_drug_spec, \n",
    "                                                  solver, \n",
    "                                                  feature_data, \n",
    "                                                  modified_parameter_sets,\n",
    "                                                  {'start': 0, 'end': 1000, 'points': 100}, \n",
    "                                                  capture_species='all', n_cores=1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9aea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_time_course_data = generate_model_timecourse_data_diff_build(model_drug_spec, \n",
    "                                                            solver,\n",
    "                                                            feature_data, \n",
    "                                                            parameter_sets, \n",
    "                                                            {'start': 0, 'end': 1000, 'points': 100}, \n",
    "                                                            capture_species='all', n_cores=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d7bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link removal time course data (sets)\n",
    "\n",
    "link_removal_time_course_datasets = []\n",
    "for link_removal_params in all_link_removal_parameters:\n",
    "    link_removal_time_course_data = generate_model_timecourse_data_diff_build(model_drug_spec, \n",
    "                                                                    solver, \n",
    "                                                                    feature_data, \n",
    "                                                                    link_removal_params, \n",
    "                                                                    {'start': 0, 'end': 1000, 'points': 100}, \n",
    "                                                                    capture_species='all', n_cores=1, verbose=True)\n",
    "    link_removal_time_course_datasets.append(link_removal_time_course_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6392e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get time axis (assuming same length for both datasets)\n",
    "n_steps = len(time_course_data['Cp'][0])\n",
    "real_time = np.linspace(0, 1000, n_steps)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot true time course (blue)\n",
    "for series in true_time_course_data['Cp']:\n",
    "    plt.plot(real_time, series, alpha=0.3, color='blue', label='True Cp' if 'True Cp' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "    \n",
    "# Plot simulated time course (red)\n",
    "for series in time_course_data['Cp']:\n",
    "    plt.plot(real_time, series, alpha=0.3, color='red', label='Simulated Cp' if 'Simulated Cp' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# Labels and formatting\n",
    "plt.title(\"Comparison of Simulated, True, and Original Cp Time Series\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Cp Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# === Set up time axis ===\n",
    "n_steps = len(time_course_data['Cp'][0])  # assumes all rows have equal length\n",
    "real_time = np.linspace(0, 1000, n_steps)\n",
    "\n",
    "# === Helper function to plot mean ± std ===\n",
    "def plot_mean_std(df, color, label, time_axis):\n",
    "    # Stack rows of lists into a 2D array: shape (n_replicates, time_steps)\n",
    "    data = np.vstack(df['Cp'].values)\n",
    "    mean = data.mean(axis=0)\n",
    "    std = data.std(axis=0)\n",
    "\n",
    "    # Plot mean line\n",
    "    plt.plot(time_axis, mean, color=color, label=label, linewidth=2)\n",
    "    # Plot shaded std band\n",
    "    plt.fill_between(time_axis, mean - std, mean + std, color=color, alpha=0.2)\n",
    "\n",
    "# === Begin Plot ===\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot mean ± std for true data\n",
    "plot_mean_std(true_time_course_data, color='blue', label='True Cp', time_axis=real_time)\n",
    "\n",
    "# Plot mean ± std for simulated data\n",
    "# plot_mean_std(time_course_data, color='red', label='Simulated Cp', time_axis=real_time)\n",
    "\n",
    "# Plot mean ± std for link removal datasets\n",
    "for i, link_removal_data in enumerate(link_removal_time_course_datasets):\n",
    "    plot_mean_std(link_removal_data, color=f'C{i+2}', label=f'Link Removal Set {i+1}', time_axis=real_time)\n",
    "\n",
    "# === Plot Settings ===\n",
    "plt.title(\"Comparison of Simulated, True, and Original Cp Time Series (Mean ± Std)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Cp Value\")\n",
    "# plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7252a10a",
   "metadata": {},
   "source": [
    "### Creating final datasets for ML Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0040f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Utils import last_time_point_method, dynamic_features_method\n",
    "\n",
    "all_species = model_drug_spec.A_species + model_drug_spec.B_species + model_drug_spec.C_species\n",
    "all_phos_species = [s+'p' for s in all_species]\n",
    "# apply the data engineering method to the feature data\n",
    "last_time_data = last_time_point_method(time_course_data, all_phos_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5be0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data = dynamic_features_method(time_course_data, all_phos_species, n_cores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aee667",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_lp_data = pd.concat([feature_data, last_time_data], axis=1)\n",
    "combined_dyn_data = pd.concat([feature_data, dynamic_data], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_list = [feature_data, last_time_data, dynamic_data, combined_lp_data, combined_dyn_data]\n",
    "feature_data_names = ['feature_data', 'last_time_data', 'dynamic_data', 'combined_lp_data', 'combined_dyn_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ca7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_time_data_link_rm = []\n",
    "dynamic_data_link_rm = []\n",
    "for zeroed_params in link_removal_time_course_datasets:\n",
    "    last_time_data_rm = last_time_point_method(zeroed_params, all_phos_species)\n",
    "    dynamic_data_rm = dynamic_features_method(zeroed_params, all_phos_species, n_cores=8)\n",
    "    last_time_data_link_rm.append(last_time_data_rm)\n",
    "    dynamic_data_link_rm.append(dynamic_data_rm)\n",
    "    \n",
    "# combine the link removal data with the feature data\n",
    "link_removal_last_time_combined = []\n",
    "link_removal_dynamic_combined = []\n",
    "for i in range(len(last_time_data_link_rm)):\n",
    "    link_removal_last_time_combined.append(pd.concat([feature_data, last_time_data_link_rm[i]], axis=1))\n",
    "    link_removal_dynamic_combined.append(pd.concat([feature_data, dynamic_data_link_rm[i]], axis=1))\n",
    "    \n",
    "# create labels for the link removal data\n",
    "link_removal_last_time_labels = [f'link_removal_{i+1}_last_time' for i in range(len(last_time_data_link_rm))]\n",
    "link_removal_dynamic_labels = [f'link_removal_{i+1}_dynamic' for i in range(len(dynamic_data_link_rm))]\n",
    "# create labels for the combined data\n",
    "combined_lp_labels = [f'link_removal_{i+1}_combined_lp' for i in range(len(link_removal_last_time_combined))]\n",
    "combined_dyn_labels = [f'link_removal_{i+1}_combined_dyn' for i in range(len(link_removal_dynamic_combined))]\n",
    "\n",
    "# add into feature_data_list and feature_data_names\n",
    "feature_data_list.extend(last_time_data_link_rm)\n",
    "feature_data_list.extend(dynamic_data_link_rm)\n",
    "feature_data_list.extend(link_removal_last_time_combined)\n",
    "feature_data_list.extend(link_removal_dynamic_combined)\n",
    "feature_data_names.extend(link_removal_last_time_labels)\n",
    "feature_data_names.extend(link_removal_dynamic_labels)\n",
    "feature_data_names.extend(combined_lp_labels)\n",
    "feature_data_names.extend(combined_dyn_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b100a37",
   "metadata": {},
   "source": [
    "### Machine Learning Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def build_pipeline(model, scale=False):\n",
    "    steps = [('imputer', SimpleImputer(strategy='mean'))]\n",
    "    if scale:\n",
    "        steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', model))\n",
    "    return Pipeline(steps)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, model_name, feature_data, feature_data_name, target_data, test_size=0.2, random_state=4):\n",
    "    # Align rows between X and y\n",
    "    common_idx = feature_data.index.intersection(target_data.index)\n",
    "    X = feature_data.loc[common_idx]\n",
    "    y = target_data.loc[common_idx]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return {\n",
    "        'Model': model_name, \n",
    "        'Feature Data': feature_data_name,\n",
    "        'Mean Squared Error': mean_squared_error(y_test, y_pred),\n",
    "        'R2 Score': r2_score(y_test, y_pred),\n",
    "        'Pearson Correlation': pearsonr(y_test, y_pred)[0],\n",
    "        'Pearson P-Value': pearsonr(y_test, y_pred)[1]\n",
    "    }\n",
    "\n",
    "all_models = [\n",
    "    build_pipeline(LinearRegression()),\n",
    "    build_pipeline(RandomForestRegressor(n_estimators=100, random_state=o_random_seed)),\n",
    "    build_pipeline(GradientBoostingRegressor(n_estimators=100, random_state=o_random_seed)),\n",
    "    build_pipeline(SVR(max_iter=10000), scale=True),\n",
    "    build_pipeline(MLPRegressor(hidden_layer_sizes=(20,), max_iter=10000, random_state=o_random_seed), scale=True)\n",
    "]\n",
    "\n",
    "all_models_desc = ['Linear Regression', 'Random Forest', 'Gradient Boosting', 'Support Vector Machine', 'Neural Network']\n",
    "zipped_model_data = list(zip(all_models, all_models_desc))\n",
    "all_features = feature_data_list\n",
    "all_features_desc = feature_data_names\n",
    "zipped_feature_data = list(zip(all_features, all_features_desc))\n",
    "\n",
    "# random states are rand ints between 0 and 10000, for n values \n",
    "np.random.seed(o_random_seed)\n",
    "n_random = 10\n",
    "all_random_states = np.random.randint(0, 10000, n_random)\n",
    "\n",
    "parallelise = True \n",
    "from tqdm import tqdm\n",
    "# tqdm is a progress bar library, use it to show the progress of the model evaluation\n",
    "metric_data = []\n",
    "if not parallelise:          \n",
    "    for (feature_data, feature_data_name) in tqdm(zipped_feature_data):\n",
    "        # print('Feature Data:', feature_data_name)\n",
    "        # print('Feature Data Shape:', feature_data.shape)\n",
    "        for (model, model_name) in zipped_model_data:\n",
    "            # print('Model:', model_name)\n",
    "            for rand in all_random_states:\n",
    "                metrics = evaluate_model(model, model_name, feature_data, feature_data_name, target_data['Cp'], random_state=rand)\n",
    "                metric_data.append(metrics)\n",
    "                \n",
    "else:        \n",
    "    # parallelise the model evaluation process using joblib\n",
    "    from joblib import Parallel, delayed\n",
    "\n",
    "    metric_data = Parallel(n_jobs=-1)(delayed(evaluate_model)(model, model_name, feature_data, feature_data_name, target_data['Cp'], random_state=rand) \n",
    "                                    for (feature_data, feature_data_name) in zipped_feature_data\n",
    "                                    for (model, model_name) in zipped_model_data\n",
    "                                    for rand in all_random_states)\n",
    "\n",
    "# make a dataframe of the metric data\n",
    "metric_df = pd.DataFrame(metric_data)\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_figures: \n",
    "    metric_df.to_pickle(experiment_folder+'metric_df.pkl')\n",
    "    print('Metric data saved to:', experiment_folder+'metric_df.pkl')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc6e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the metric data\n",
    "import pandas as pd \n",
    "metric_df = pd.read_pickle(experiment_folder+'metric_df.pkl')\n",
    "print('Metric data loaded from:', experiment_folder+'metric_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b10a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Apply regex to extract parts from 'Feature Data'\n",
    "def extract_link_removal_parts(feature_str):\n",
    "    match = re.match(r'(link_removal_(\\d+)_([\\w]+))', feature_str)\n",
    "    if match:\n",
    "        full_name = match.group(1)\n",
    "        removed_links = int(match.group(2))\n",
    "        data_type = match.group(3)\n",
    "        return pd.Series([full_name, removed_links, data_type])\n",
    "    else:\n",
    "        return pd.Series([feature_str, None, None])  # fallback for non-matching entries\n",
    "\n",
    "# Apply to metric_df\n",
    "metric_df[['Full name', 'Removed links', 'Type']] = metric_df['Feature Data'].apply(extract_link_removal_parts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522895a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the pearson correlation for each feature data combination\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(120, 6))\n",
    "# Create a boxplot for Pearson Correlation\n",
    "sns.boxplot(data=metric_df, x='Feature Data', y='Pearson Correlation', hue='Feature Data')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Pearson Correlation by Feature Data and Model')\n",
    "plt.xlabel('Feature Data')\n",
    "plt.ylabel('Pearson Correlation')\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a50c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL missing values of Pearson Correlation with 0 \n",
    "metric_df['Pearson Correlation'] = metric_df['Pearson Correlation'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_context(\"talk\", rc={\"font\": \"Arial\"})\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Group and average\n",
    "grouped = (\n",
    "    metric_df\n",
    "    .dropna(subset=['Removed links', 'Pearson Correlation', 'Type'])\n",
    "    .groupby(['Removed links', 'Type'])\n",
    "    .agg(mean_corr=('Pearson Correlation', 'mean'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=grouped, x='Removed links', y='mean_corr', hue='Type', marker='o')\n",
    "plt.title('Mean Pearson Correlation vs Removed Links')\n",
    "plt.xlabel('Number of Links Removed')\n",
    "plt.ylabel('Mean Pearson Correlation')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
